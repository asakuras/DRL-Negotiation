{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math, os\n",
    "from itertools import product\n",
    "from multiprocessing import Pool\n",
    "from functions import*\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import torch.multiprocessing as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from mpl_toolkits import mplot3d\n",
    "import copy\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_DIM  = 4\n",
    "H1_DIM = 128\n",
    "H2_DIM = 512\n",
    "REC_DIM = 2\n",
    "OFF_DIM = 1\n",
    "V_DIM = 1\n",
    "LR = 0.0001\n",
    "EPISODES = 100000\n",
    "DEADLINE = 20\n",
    "DISCOUNTS = list(np.linspace(0,1,21))\n",
    "torch.manual_seed(7)\n",
    "\n",
    "class boulware(object):\n",
    "    def __init__(self,V,T, c,r):\n",
    "        self.V = V\n",
    "        self.T = T\n",
    "        self.c = c\n",
    "        self.r = r\n",
    "    \n",
    "    def calc_Ft(self,t):\n",
    "        return (t/self.T)**(1/self.c)\n",
    "\n",
    "    def calc_decision_util(self,t):\n",
    "        Ft = self.calc_Ft(t)\n",
    "        ut = self.r + (1 - self.r)*(1-Ft)\n",
    "        return ut\n",
    "    \n",
    "    def generate_offer(self,t):\n",
    "        # How to decide which axis to concede.\n",
    "        ut = self.calc_decision_util(t)\n",
    "        ut *= torch.sum(self.V)\n",
    "        \n",
    "        X = torch.clamp((ut / V[0]) + np.random.normal(scale=0.05) ,0,1)\n",
    "        if X == 1:\n",
    "            ut -= X*V[0]\n",
    "            Y = torch.clamp((ut / V[1])+ np.random.normal(scale=0.05) ,0,1)\n",
    "            if Y == 1:\n",
    "                ut -= Y*V[1]\n",
    "                Z = torch.clamp((ut / V[2])+ np.random.normal(scale=0.05) ,0,1)\n",
    "            else:\n",
    "                Z = 0\n",
    "        else:\n",
    "            Y = Z = 0\n",
    "        \n",
    "#         print(torch.Tensor([X,Y,Z]))\n",
    "        return torch.Tensor([X,Y,Z,t])\n",
    "\n",
    "    def receive(self,offer,t):\n",
    "        my_offer = 1-offer\n",
    "        ut = self.calc_decision_util(t)\n",
    "        ut *= torch.sum(self.V)\n",
    "        if torch.sum(self.V * my_offer) > ut:\n",
    "            return torch.Tensor([1])\n",
    "        else:\n",
    "            return torch.Tensor([0])\n",
    "\n",
    "\n",
    "class ON_Cauchy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ON_Cauchy, self).__init__()\n",
    "        \n",
    "        self.V = torch.Tensor([[1,2,3]])\n",
    "        self.name = \"CAUCHY\"\n",
    "\n",
    "        self.L1 = nn.Linear(X_DIM,H1_DIM)\n",
    "\n",
    "        self.base = nn.Sequential(\n",
    "            nn.Linear(H1_DIM, H2_DIM),\n",
    "            nn.ReLU6(),\n",
    "#             nn.Linear(H2_DIM, H2_DIM),\n",
    "#             nn.ReLU6(),\n",
    "        )\n",
    "\n",
    "        self.muX = nn.Sequential(\n",
    "            nn.Linear(H1_DIM, H2_DIM),\n",
    "            nn.ReLU6(),\n",
    "            nn.Linear(H2_DIM, H2_DIM),\n",
    "            nn.ReLU6(),\n",
    "            nn.Linear(H2_DIM, OFF_DIM),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.sigX = nn.Sequential(\n",
    "            nn.Linear(H1_DIM, H2_DIM),\n",
    "            nn.ReLU6(),\n",
    "            nn.Linear(H2_DIM, OFF_DIM),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.muY = nn.Sequential(\n",
    "            nn.Linear(H1_DIM, H2_DIM),\n",
    "            nn.ReLU6(),\n",
    "            nn.Linear(H2_DIM, H2_DIM),\n",
    "            nn.ReLU6(),\n",
    "            nn.Linear(H2_DIM, OFF_DIM),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.sigY = nn.Sequential(\n",
    "            nn.Linear(H1_DIM, H2_DIM),\n",
    "            nn.ReLU6(),\n",
    "            nn.Linear(H2_DIM, OFF_DIM),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.muZ = nn.Sequential(\n",
    "            nn.Linear(H1_DIM, H2_DIM),\n",
    "            nn.ReLU6(),\n",
    "           nn.Linear(H2_DIM, H2_DIM),\n",
    "            nn.ReLU6(),\n",
    "            nn.Linear(H2_DIM, OFF_DIM),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.sigZ = nn.Sequential(\n",
    "            nn.Linear(H1_DIM, H2_DIM),\n",
    "            nn.ReLU6(),\n",
    "            nn.Linear(H2_DIM, OFF_DIM),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.m_rec = torch.distributions.Categorical\n",
    "        self.m_X = torch.distributions.cauchy.Cauchy\n",
    "        \n",
    "        \n",
    "        self.m_Y = torch.distributions.cauchy.Cauchy\n",
    "        self.m_Z = torch.distributions.cauchy.Cauchy\n",
    "\n",
    "        self.value = nn.Sequential(\n",
    "            nn.Linear(H2_DIM, H2_DIM),\n",
    "            nn.ReLU6(),\n",
    "            nn.Linear(H2_DIM, H2_DIM),\n",
    "            nn.ReLU6(),\n",
    "#             nn.Linear(H2_DIM, H2_DIM),\n",
    "#             nn.ReLU6(),\n",
    "            nn.Linear(H2_DIM, V_DIM),\n",
    "        )\n",
    "\n",
    "        set_init([self.base, self.muX, self.sigX, self.muY, self.sigY, \n",
    "                  self.muZ, self.sigZ, self.value])\n",
    "\n",
    "    def forward(self, x):\n",
    "#         out, __ = self.lstm(x)\n",
    "        out  = self.L1(x)\n",
    "        muX  = torch.clamp(self.muX(out), 0.02, 0.98)\n",
    "        sigX = torch.clamp(self.sigX(out), 0.001, 0.02)\n",
    "        muY  = torch.clamp(self.muY(out), 0.02, 0.98)\n",
    "        sigY = torch.clamp(self.sigY(out), 0.001, 0.02)\n",
    "        muZ  = torch.clamp(self.muZ(out), 0.02, 0.98)\n",
    "        sigZ = torch.clamp(self.sigZ(out), 0.001, 0.02)\n",
    "        out     = self.base(out)\n",
    "        return muX, sigX, muY, sigY, muZ, sigZ, self.value(out)\n",
    "    # Decision, offer, value\n",
    "\n",
    "    def choose_action(self,x,show=False):\n",
    "        muX, sigX, muY, sigY, muZ, sigZ, __= self.forward(x)\n",
    "\n",
    "        ### Select offer ###\n",
    "        distX = self.m_X(muX.squeeze(), sigX.squeeze())\n",
    "        distY = self.m_Y(muY.squeeze(), sigY.squeeze())\n",
    "        distZ = self.m_Z(muZ.squeeze(), sigZ.squeeze())\n",
    "        X, Y, Z = distX.rsample(), distY.rsample(), distZ.rsample()      \n",
    "        X, Y, Z = torch.clamp(X, 0.10, 1), torch.clamp(Y, 0.10, 1), torch.clamp(Z, 0.10, 1)\n",
    "        offer = torch.Tensor([X,Y,Z])\n",
    "\n",
    "        if show:\n",
    "            print(\"Logit\", logits)\n",
    "            print(\"X: \", muX, sigX)\n",
    "            print(\"Y: \", muY, sigY)\n",
    "            print(\"Z: \", muZ, sigZ)\n",
    "        return offer\n",
    "    \n",
    "class ON_Normal(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ON_Normal, self).__init__()\n",
    "        \n",
    "        self.V = torch.Tensor([[1,2,3]])\n",
    "        self.name = \"NORMAL\"\n",
    "\n",
    "        self.lstm = nn.Linear(X_DIM,H1_DIM)\n",
    "\n",
    "        self.base = nn.Sequential(\n",
    "            nn.Linear(H1_DIM, H2_DIM),\n",
    "            nn.ReLU6(),\n",
    "#             nn.Linear(H2_DIM, H2_DIM),\n",
    "#             nn.ReLU6(),\n",
    "        )\n",
    "\n",
    "        self.muX = nn.Sequential(\n",
    "            nn.Linear(H1_DIM, H2_DIM),\n",
    "            nn.ReLU6(),\n",
    "            nn.Linear(H2_DIM, H2_DIM),\n",
    "            nn.ReLU6(),\n",
    "            nn.Linear(H2_DIM, OFF_DIM),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.sigX = nn.Sequential(\n",
    "            nn.Linear(H1_DIM, H2_DIM),\n",
    "            nn.ReLU6(),\n",
    "            nn.Linear(H2_DIM, OFF_DIM),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.muY = nn.Sequential(\n",
    "            nn.Linear(H1_DIM, H2_DIM),\n",
    "            nn.ReLU6(),\n",
    "            nn.Linear(H2_DIM, H2_DIM),\n",
    "            nn.ReLU6(),\n",
    "            nn.Linear(H2_DIM, OFF_DIM),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.sigY = nn.Sequential(\n",
    "            nn.Linear(H1_DIM, H2_DIM),\n",
    "            nn.ReLU6(),\n",
    "            nn.Linear(H2_DIM, OFF_DIM),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.muZ = nn.Sequential(\n",
    "            nn.Linear(H1_DIM, H2_DIM),\n",
    "            nn.ReLU6(),\n",
    "           nn.Linear(H2_DIM, H2_DIM),\n",
    "            nn.ReLU6(),\n",
    "            nn.Linear(H2_DIM, OFF_DIM),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.sigZ = nn.Sequential(\n",
    "            nn.Linear(H1_DIM, H2_DIM),\n",
    "            nn.ReLU6(),\n",
    "            nn.Linear(H2_DIM, OFF_DIM),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.m_rec = torch.distributions.Categorical\n",
    "        self.m_X = torch.distributions.Normal\n",
    "        self.m_Y = torch.distributions.Normal\n",
    "        self.m_Z = torch.distributions.Normal\n",
    "\n",
    "        self.value = nn.Sequential(\n",
    "            nn.Linear(H2_DIM, H2_DIM),\n",
    "            nn.ReLU6(),\n",
    "            nn.Linear(H2_DIM, H2_DIM),\n",
    "            nn.ReLU6(),\n",
    "            nn.Linear(H2_DIM, H2_DIM),\n",
    "            nn.ReLU6(),\n",
    "            nn.Linear(H2_DIM, V_DIM),\n",
    "        )\n",
    "\n",
    "        set_init([self.base, self.muX, self.sigX, self.muY, self.sigY, \n",
    "                  self.muZ, self.sigZ, self.value])\n",
    "\n",
    "    def forward(self, x):\n",
    "#         out, __ = self.lstm(x)\n",
    "        out  = self.lstm(x)\n",
    "        muX  = torch.clamp(self.muX(out), 0.02, 0.98)\n",
    "        sigX = torch.clamp(self.sigX(out), 0.001, 0.02)\n",
    "        muY  = torch.clamp(self.muY(out), 0.02, 0.98)\n",
    "        siagY = torch.clamp(self.sigY(out), 0.001, 0.02)\n",
    "        muZ  = torch.clamp(self.muZ(out), 0.02, 0.98)\n",
    "        sigZ = torch.clamp(self.sigZ(out), 0.001, 0.02)\n",
    "        out     = self.base(out)\n",
    "        return muX, sigX, muY, sigY, muZ, sigZ, self.value(out)\n",
    "    # Decision, offer, value\n",
    "\n",
    "    def choose_action(self,x,show=False):\n",
    "        muX, sigX, muY, sigY, muZ, sigZ, __= self.forward(x)\n",
    "\n",
    "        ### Select offer ###\n",
    "        distX = self.m_X(muX.squeeze(), sigX.squeeze())\n",
    "        distY = self.m_Y(muY.squeeze(), sigY.squeeze())\n",
    "        distZ = self.m_Z(muZ.squeeze(), sigZ.squeeze())\n",
    "        X, Y, Z = distX.rsample(), distY.rsample(), distZ.rsample()      \n",
    "        X, Y, Z = torch.clamp(X, 0.10, 1), torch.clamp(Y, 0.10, 1), torch.clamp(Z, 0.10, 1)\n",
    "        offer = torch.Tensor([X,Y,Z])\n",
    "\n",
    "        if show:\n",
    "            print(\"Logit\", logits)\n",
    "            print(\"X: \", muX, sigX)\n",
    "            print(\"Y: \", muY, sigY)\n",
    "            print(\"Z: \", muZ, sigZ)\n",
    "        return offer\n",
    "\n",
    "class ON_Beta(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ON_Beta, self).__init__()\n",
    "        \n",
    "        self.V = torch.Tensor([[1,2,3]])\n",
    "        self.name = \"BETA\"\n",
    "        self.base = nn.Sequential(\n",
    "            nn.Linear(X_DIM, H1_DIM),\n",
    "            nn.ReLU(),\n",
    "#             nn.Linear(H1_DIM, H2_DIM),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(H2_DIM, H2_DIM),\n",
    "#             nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.alphaX = nn.Sequential(\n",
    "            nn.Linear(H1_DIM, H2_DIM),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(H2_DIM, H2_DIM),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(H2_DIM, OFF_DIM),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "        \n",
    "        self.betaX = nn.Sequential(\n",
    "            nn.Linear(H1_DIM, H2_DIM),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(H2_DIM, H2_DIM),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(H2_DIM, OFF_DIM),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "        \n",
    "        self.alphaY = nn.Sequential(\n",
    "            nn.Linear(H1_DIM, H2_DIM),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(H2_DIM, H2_DIM),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(H2_DIM, OFF_DIM),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "        \n",
    "        self.betaY = nn.Sequential(\n",
    "            nn.Linear(H1_DIM, H2_DIM),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(H2_DIM, H2_DIM),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(H2_DIM, OFF_DIM),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "        \n",
    "        self.alphaZ = nn.Sequential(\n",
    "            nn.Linear(H1_DIM, H2_DIM),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(H2_DIM, H2_DIM),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(H2_DIM, OFF_DIM),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "        \n",
    "        self.betaZ = nn.Sequential(\n",
    "            nn.Linear(H1_DIM, H2_DIM),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(H2_DIM, H2_DIM),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(H2_DIM, OFF_DIM),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "        \n",
    "        self.m_X = torch.distributions.beta.Beta\n",
    "        self.m_Y = torch.distributions.beta.Beta\n",
    "        self.m_Z = torch.distributions.beta.Beta\n",
    "        \n",
    "        self.value = nn.Sequential(\n",
    "            nn.Linear(H1_DIM, H2_DIM),\n",
    "            nn.ReLU6(),\n",
    "            nn.Linear(H2_DIM, H2_DIM),\n",
    "            nn.ReLU6(),\n",
    "            nn.Linear(H2_DIM, H2_DIM),\n",
    "            nn.ReLU6(),\n",
    "            nn.Linear(H2_DIM, V_DIM),\n",
    "        )\n",
    "        \n",
    "        set_init([self.base, self.alphaX, self.betaX, self.alphaY, self.betaY, \n",
    "                  self.alphaZ, self.betaZ, self.value])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.base(x)\n",
    "        aX  = torch.clamp(self.alphaX(out), 0, 2000)\n",
    "        bX = torch.clamp(self.betaX(out), 0, 2000)\n",
    "        aY  = torch.clamp(self.alphaY(out), 0, 2000)\n",
    "        bY = torch.clamp(self.betaY(out), 0, 2000)\n",
    "        aZ  = torch.clamp(self.alphaZ(out), 0, 2000)\n",
    "        bZ = torch.clamp(self.betaZ(out), 0, 2000)\n",
    "        return aX, bX, aY, bY, aZ, bZ, self.value(out)\n",
    "    \n",
    "    def choose_action(self,x):\n",
    "        self.training = False\n",
    "        aX, bX, aY, bY, aZ, bZ, __  = self.forward(x)\n",
    "        distX = self.m_X(aX.squeeze() + 1, bX.squeeze() + 1)\n",
    "        distY = self.m_Y(aY.squeeze() + 1, bY.squeeze() + 1)\n",
    "        distZ = self.m_Z(aZ.squeeze() + 1, bZ.squeeze() + 1)\n",
    "        X, Y, Z = distX.rsample(), distY.rsample(), distZ.rsample()      \n",
    "        X, Y, Z = torch.clamp(X, 0.10, 1), torch.clamp(Y, 0.10, 1), torch.clamp(Z, 0.10, 1)\n",
    "        offer = torch.Tensor([X,Y,Z])\n",
    "        return offer\n",
    "\n",
    "def calc_rewards(P_res, actions, own_v, opp_v):\n",
    "    receiving = 1 - actions\n",
    "    own_ut = torch.sum(actions   * own_v, dim=1,keepdim=True)   \n",
    "    opp_ut = torch.sum(receiving * opp_v, dim=1,keepdim=True)   \n",
    "    rewards = own_ut * (P_res < opp_ut).float()\n",
    "    return rewards    \n",
    "    \n",
    "def train(num_episodes,c,discount,P_res,LR=0.0001):\n",
    "    torch.manual_seed(7)\n",
    "    V = torch.Tensor([3,2,1])\n",
    "    T = 20\n",
    "    r = 0.0\n",
    "    gamma = 0.98\n",
    "    a = boulware(V,T,c,r)\n",
    "    Net = ON_Normal()\n",
    "    optimizer = optim.Adam(Net.parameters(),\n",
    "                               lr=LR)\n",
    "    losses = np.zeros(num_episodes)\n",
    "    rewards_aggregate = np.zeros(num_episodes)\n",
    "    times = np.zeros(num_episodes)\n",
    "    start = time.time()\n",
    "    loss = 0\n",
    "\n",
    "    path = \"c{}-d{}\".format(c,discount)\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "        os.mkdir(path+\"/data\")\n",
    "\n",
    "    for ep in range(num_episodes):\n",
    "        if ep % 500 == 0:\n",
    "            print(\"Epoch \", ep, \"  with loss at \", loss)\n",
    "            print(\"Episode Time is: \", time.time() - start)\n",
    "            start = time.time()\n",
    "#             output_training_metrics(ep,Net,a,path)\n",
    "\n",
    "        states_tensor = X\n",
    "        actions_tensor = Net.choose_action(states_tensor)\n",
    "        rewards_tensor = calc_rewards(P_res, actions_tensor, Net.V, a.V)\n",
    "\n",
    "        muX, sigX, muY, sigY, muZ, sigZ, vals = Net(states_tensor)\n",
    "        # Critic Loss\n",
    "        td = rewards_tensor - vals\n",
    "        c_loss = td.pow(2)\n",
    "        \n",
    "        m_X = Net.m_X(muX, sigX)\n",
    "        log_prob = m_X.log_prob(actions_tensor[:,0].unsqueeze(1))\n",
    "        entropy = 0.5 + 0.5 * math.log(2 * math.pi) + torch.log(m_X.scale)  # exploration\n",
    "        exp_v = log_prob * td.detach() + 0.005 * entropy ## Take out the entropy if you have some issues\n",
    "        a_X_loss = -exp_v\n",
    "\n",
    "        m_Y = Net.m_Y(muY, muY)\n",
    "        log_prob = m_Y.log_prob(actions_tensor[:,1].unsqueeze(1))\n",
    "        entropy = 0.5 + 0.5 * math.log(2 * math.pi) + torch.log(m_Y.scale)  # exploration\n",
    "        exp_v = log_prob * td.detach() + 0.005 * entropy\n",
    "        a_Y_loss = -exp_v\n",
    "\n",
    "        m_Z = Net.m_Z(muZ, muZ)\n",
    "        log_prob = m_Z.log_prob(actions_tensor[:,2].unsqueeze(1))\n",
    "        entropy = 0.5 + 0.5 * math.log(2 * math.pi) + torch.log(m_Z.scale)  # exploration\n",
    "        exp_v = log_prob * td.detach() + 0.005 * entropy\n",
    "        a_Z_loss = -exp_v\n",
    "\n",
    "        a_loss = a_X_loss + a_Y_loss + a_Z_loss\n",
    "        \n",
    "        loss = (c_loss + a_loss).mean()\n",
    "        losses[ep] = loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        a_X_loss.mean().backward(retain_graph = True)\n",
    "        a_Y_loss.mean().backward(retain_graph = True)\n",
    "        a_Z_loss.mean().backward(retain_graph = True)\n",
    "#         a_loss.mean().backward(retain_graph = True)\n",
    "        c_loss.mean().backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    np.save(path + \"/c{}-d{}-losses\".format(c,discount), losses)\n",
    "    np.save(path + \"/c{}-d{}-times\".format(c,discount),  times)\n",
    "    np.save(path + \"/c{}-d{}-rewards\".format(c,discount),  rewards_aggregate)\n",
    "    torch.save(Net.state_dict(),path + \".th\")\n",
    "    return Net, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 0.0\n",
    "T = 20\n",
    "V = torch.Tensor([3,2,1])\n",
    "c_list = [3.0]\n",
    "X = []\n",
    "P_res = []\n",
    "\n",
    "for c in c_list:\n",
    "    a = boulware(V,T,c,r)\n",
    "    for t in range(T):\n",
    "        state = a.generate_offer(t) # what the agent sees\n",
    "        uts = a.calc_decision_util(t)\n",
    "        X.append(state)\n",
    "        P_res.append(torch.Tensor([uts*6]))\n",
    "        \n",
    "P_res = torch.stack(P_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0   with loss at  0\n",
      "Episode Time is:  0.0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-446cc754f5d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mNet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mP_res\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-ddb76155d7e0>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(num_episodes, c, discount, P_res, LR)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m         \u001b[0mstates_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m         \u001b[0mactions_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoose_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m         \u001b[0mrewards_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalc_rewards\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mP_res\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-ddb76155d7e0>\u001b[0m in \u001b[0;36mchoose_action\u001b[1;34m(self, x, show)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mchoose_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m         \u001b[0mmuX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmuY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmuZ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigZ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m__\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m         \u001b[1;31m### Select offer ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-ddb76155d7e0>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;31m#         out, __ = self.lstm(x)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[0mout\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m         \u001b[0mmuX\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmuX\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.02\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.98\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[0msigX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigX\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.02\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\networks\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\networks\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\networks\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1670\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mTensor\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtens_ops\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtens_ops\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1671\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtens_ops\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1672\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1673\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1674\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "Net, losses = train(100,3.0,1.0, P_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
